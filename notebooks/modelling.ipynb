{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.18.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already up-to-date: imbalanced-learn in /opt/conda/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn) (0.14.1)\n",
      "Requirement already satisfied: hyperopt in /opt/conda/lib/python3.7/site-packages (0.2.7)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: py4j in /opt/conda/lib/python3.7/site-packages (from hyperopt) (0.10.9.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from hyperopt) (1.18.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from hyperopt) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from hyperopt) (1.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from hyperopt) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from hyperopt) (2.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from hyperopt) (4.43.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.2->hyperopt) (4.4.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost\n",
    "! pip install -U imbalanced-learn\n",
    "! pip install hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Essential modules for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Custom modules to assist the commom data exploration and preparation tasks\n",
    "import src.data.sets as datasets\n",
    "\n",
    "# Custom module to produce Baseline assement\n",
    "import src.models.null as basemodel\n",
    "\n",
    "# Custom module to produced Performance metrics\n",
    "import src.models.performance as perf\n",
    "\n",
    "# Classifiers\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Pytorch Modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Neural Network Modules\n",
    "from src.models.pytorch import PytorchDataset\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "from src.models.pytorch import get_device\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "# Classifier Tuning\n",
    "from hyperopt import Trials, STATUS_OK, tpe, hp, fmin\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV,KFold\n",
    "\n",
    "# Modules to persist classes\n",
    "import joblib\n",
    "\n",
    "# Time related modules\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Declare variables to store name of timezone\n",
    "tz_SYD = pytz.timezone('Australia/Sydney')\n",
    "\n",
    "## Set module auto reload options\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Collect processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set(s) into dataframe(s)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = datasets.load_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataframe (rows, columns):  (467746, 6)\n",
      "Validation Dataframe (rows, columns):  (155916, 6)\n",
      "Test Dataframe (rows, columns):  (155916, 6)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the loaded datasets to verify that correct data has been loaded\n",
    "print(\"Train Dataframe (rows, columns): \", X_train.shape)\n",
    "print(\"Validation Dataframe (rows, columns): \", X_val.shape)\n",
    "print(\"Test Dataframe (rows, columns): \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Assess Baseline of Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set Name</th>\n",
       "      <th>ACC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>0.060471</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.990966</td>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Set Name       ACC      PREC    RECALL        F1\n",
       "0     Base  0.060471  0.009615  0.990966  0.001097"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a Base Classification Model\n",
    "base = basemodel.NullModel(target_type=\"classification\")\n",
    "# Make Predictions on the Model\n",
    "y_base_preds = base.fit_predict(y_train)\n",
    "# Score the Base Model\n",
    "perf.score_null_model(y_train, y_base_preds, \"Base\", \"multiclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Observations:**\n",
    ">* Accuracy score of base model is very low at 6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Train various models with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************\n",
      "2022-03-20 19:32:11.995593+11:00 - Start fit and score for model:  XGBoost\n",
      "2022-03-20 19:45:26.422980+11:00 - End fit for model:  XGBoost\n",
      "2022-03-20 19:45:26.423247+11:00 - Make train preds for model:  XGBoost\n",
      "2022-03-20 19:45:45.220909+11:00 - Make val preds for model:  XGBoost\n",
      "2022-03-20 19:45:52.344902+11:00 - End fit and score for model:  XGBoost\n",
      "*******************************\n",
      "                               \n",
      "*******************************\n",
      "2022-03-20 19:45:52.346165+11:00 - Start fit and score for model:  KNN\n",
      "2022-03-20 19:45:53.038193+11:00 - End fit for model:  KNN\n",
      "2022-03-20 19:45:53.038661+11:00 - Make train preds for model:  KNN\n",
      "2022-03-20 19:46:17.968723+11:00 - Make val preds for model:  KNN\n",
      "2022-03-20 19:46:27.710537+11:00 - End fit and score for model:  KNN\n",
      "*******************************\n",
      "                               \n",
      "*******************************\n",
      "2022-03-20 19:46:27.711307+11:00 - Start fit and score for model:  HistGradientBoosting\n",
      "2022-03-20 19:50:44.594723+11:00 - End fit for model:  HistGradientBoosting\n",
      "2022-03-20 19:50:44.595208+11:00 - Make train preds for model:  HistGradientBoosting\n",
      "2022-03-20 19:50:55.742588+11:00 - Make val preds for model:  HistGradientBoosting\n",
      "2022-03-20 19:51:03.875349+11:00 - End fit and score for model:  HistGradientBoosting\n",
      "*******************************\n",
      "                               \n",
      "*******************************\n",
      "2022-03-20 19:51:03.876069+11:00 - Start fit and score for model:  BalancedBagging\n",
      "2022-03-20 19:51:54.046664+11:00 - End fit for model:  BalancedBagging\n",
      "2022-03-20 19:51:54.046860+11:00 - Make train preds for model:  BalancedBagging\n",
      "2022-03-20 19:53:41.782726+11:00 - Make val preds for model:  BalancedBagging\n",
      "2022-03-20 19:54:24.285553+11:00 - End fit and score for model:  BalancedBagging\n",
      "*******************************\n",
      "                               \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>t_ACC</th>\n",
       "      <th>v_ACC</th>\n",
       "      <th>t_PREC</th>\n",
       "      <th>v_PREC</th>\n",
       "      <th>t_RECALL</th>\n",
       "      <th>v_RECALL</th>\n",
       "      <th>t_F1</th>\n",
       "      <th>v_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.691360</td>\n",
       "      <td>0.652601</td>\n",
       "      <td>0.744925</td>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.700858</td>\n",
       "      <td>0.640138</td>\n",
       "      <td>0.719348</td>\n",
       "      <td>0.659655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.680104</td>\n",
       "      <td>0.521698</td>\n",
       "      <td>0.714844</td>\n",
       "      <td>0.547670</td>\n",
       "      <td>0.640714</td>\n",
       "      <td>0.489971</td>\n",
       "      <td>0.668392</td>\n",
       "      <td>0.510908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "      <td>0.453580</td>\n",
       "      <td>0.443489</td>\n",
       "      <td>0.475392</td>\n",
       "      <td>0.459867</td>\n",
       "      <td>0.426151</td>\n",
       "      <td>0.412508</td>\n",
       "      <td>0.435544</td>\n",
       "      <td>0.420908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BalancedBagging</td>\n",
       "      <td>0.281375</td>\n",
       "      <td>0.270761</td>\n",
       "      <td>0.276561</td>\n",
       "      <td>0.265689</td>\n",
       "      <td>0.465464</td>\n",
       "      <td>0.441564</td>\n",
       "      <td>0.285961</td>\n",
       "      <td>0.274208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model     t_ACC     v_ACC    t_PREC    v_PREC  t_RECALL  \\\n",
       "0               XGBoost  0.691360  0.652601  0.744925  0.687157  0.700858   \n",
       "1                   KNN  0.680104  0.521698  0.714844  0.547670  0.640714   \n",
       "2  HistGradientBoosting  0.453580  0.443489  0.475392  0.459867  0.426151   \n",
       "3       BalancedBagging  0.281375  0.270761  0.276561  0.265689  0.465464   \n",
       "\n",
       "   v_RECALL      t_F1      v_F1  \n",
       "0  0.640138  0.719348  0.659655  \n",
       "1  0.489971  0.668392  0.510908  \n",
       "2  0.412508  0.435544  0.420908  \n",
       "3  0.441564  0.285961  0.274208  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a dictionary of default models to fit and score\n",
    "models_to_fit = {\"XGBoost\": xgb.XGBClassifier(random_state=8, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "                 \"KNN\": KNeighborsClassifier(),\n",
    "                 \"HistGradientBoosting\": HistGradientBoostingClassifier(random_state=8),\n",
    "                 \"BalancedBagging\": BalancedBaggingClassifier(base_estimator=HistGradientBoostingClassifier(random_state=8), random_state=8, n_estimators=10, n_jobs=2)}\n",
    "# Fit and score the models\n",
    "perf.fit_score_models (models_to_fit, X_train, y_train, X_val, y_val, \"multiclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Observations:**\n",
    ">* Default XGBoost model accuracy is much higher than Base model but is overfitting\n",
    ">* KNN model accuracy is also mulch higher than the Base model but display a higher degree of overfitting than XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 XGBoost Model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Compute balanced class weights for the dataset and train XGBoost with calculated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-20 19:56:15.603323+11:00\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              eval_metric='mlogloss', gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
      "              random_state=8, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, ...)\n",
      "2022-03-20 20:08:09.580150+11:00\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now(tz_SYD))\n",
    "# Calculate balanced class weights to be used in training XGB\n",
    "class_weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "# Instantiate XGB Classifier\n",
    "clf_xgb1 = xgb.XGBClassifier(random_state=8, use_label_encoder=False, eval_metric='mlogloss')\n",
    "# Fit XGB Classifier with calculated class weights\n",
    "clf_xgb1.fit(X_train, y_train, sample_weight=class_weights)\n",
    "print(clf_xgb1)\n",
    "print(datetime.now(tz_SYD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set Name</th>\n",
       "      <th>ACC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.093777</td>\n",
       "      <td>0.643670</td>\n",
       "      <td>0.159429</td>\n",
       "      <td>0.055717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validate</td>\n",
       "      <td>0.091267</td>\n",
       "      <td>0.652071</td>\n",
       "      <td>0.149104</td>\n",
       "      <td>0.053539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Set Name       ACC      PREC    RECALL        F1\n",
       "0     Train  0.093777  0.643670  0.159429  0.055717\n",
       "1  Validate  0.091267  0.652071  0.149104  0.053539"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score XGB Classifier\n",
    "perf.score_models(X_train, y_train, X_val, y_val, pd.DataFrame(), pd.DataFrame(), None, False, \"multiclass\", clf_xgb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Observations:**\n",
    ">* Accuracy is much lower than default XGBoost model but higher than Base model.\n",
    ">* There is a slight degree of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Tune XGBoost with Hyperopt to find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space for XGB Hyperopt tuning\n",
    "xgbspace = {\n",
    "    'max_depth' : hp.choice('max_depth', range(5, 10, 1)),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.05),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.05),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.05)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective for XGB Hyperopt tuning\n",
    "def xgbobjective(space):   \n",
    "    xgboost = xgb.XGBClassifier(\n",
    "        max_depth = int(space['max_depth']),\n",
    "        learning_rate = space['learning_rate'],\n",
    "        min_child_weight = space['min_child_weight'],\n",
    "        subsample = space['subsample'],\n",
    "        colsample_bytree = space['colsample_bytree'],\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss'\n",
    "    )    \n",
    "    xgboost.fit(X_train, y_train)\n",
    "    y_preds = xgboost.predict(X_train)\n",
    "    acc = accuracy_score(y_train, y_preds)\n",
    "    return{'loss': 1-acc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-19 15:37:14.731559+11:00\n",
      "[04:37:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:58:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:10:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:23:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:35:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 5/5 [1:08:56<00:00, 827.38s/trial, best loss: 0.3398917361131897]\n",
      "2022-03-19 16:46:11.624516+11:00\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now(tz_SYD))\n",
    "# Perform Hyperopt search and return best parameters after 5 iterations\n",
    "xgbbest = fmin(\n",
    "    fn=xgbobjective,   \n",
    "    space=xgbspace,       \n",
    "    algo=tpe.suggest,       \n",
    "    max_evals=5\n",
    ")\n",
    "print(datetime.now(tz_SYD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:  {'colsample_bytree': 0.75, 'learning_rate': 0.2, 'max_depth': 4, 'min_child_weight': 4.0, 'subsample': 0.4}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best XGB: \", xgbbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate XGB Classifier with best Hyperopt Params\n",
    "clf_xgb2 = xgb.XGBClassifier(\n",
    "    max_depth = best['max_depth'],\n",
    "    learning_rate = best['learning_rate'],\n",
    "    min_child_weight = best['min_child_weight'],\n",
    "    subsample = best['subsample'],\n",
    "    colsample_bytree = best['colsample_bytree'],\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.75,\n",
       "              enable_categorical=False, eval_metric='mlogloss', gamma=0,\n",
       "              gpu_id=-1, importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.2, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=4.0, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=0.4,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, ...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datetime.now(tz_SYD))\n",
    "# Fit XGB Classifier with best Hyperopt Params\n",
    "clf_xgb2.fit(X_train, y_train)\n",
    "print(datetime.now(tz_SYD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set Name</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>PREC</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.447670</td>\n",
       "      <td>34.295791</td>\n",
       "      <td>19.715239</td>\n",
       "      <td>0.447670</td>\n",
       "      <td>0.447670</td>\n",
       "      <td>0.447670</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validate</td>\n",
       "      <td>0.438121</td>\n",
       "      <td>34.497455</td>\n",
       "      <td>19.988141</td>\n",
       "      <td>0.438121</td>\n",
       "      <td>0.438121</td>\n",
       "      <td>0.438121</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.433515</td>\n",
       "      <td>34.807561</td>\n",
       "      <td>20.250314</td>\n",
       "      <td>0.433515</td>\n",
       "      <td>0.433515</td>\n",
       "      <td>0.433515</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Set Name      ACC       MSE       MAE     PREC   RECALL       F1   AUC\n",
       "0     Train 0.447670 34.295791 19.715239 0.447670 0.447670 0.447670  None\n",
       "1  Validate 0.438121 34.497455 19.988141 0.438121 0.438121 0.438121  None\n",
       "2      Test 0.433515 34.807561 20.250314 0.433515 0.433515 0.433515  None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score XGB Classifier\n",
    "perf.score_models(X_train, y_train, X_val, y_val, X_test, y_test, None, False, \"multiclass\", clf_xgb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Observations:**\n",
    ">* Accuracy is much lower than default XGBoost model but higher than Base model.\n",
    ">* This model shows a very slight degree of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.3 Train and assess default XGB Model and save for deployment to production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-20 20:12:33.781737+11:00\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              eval_metric='mlogloss', gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
      "              random_state=8, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, ...)\n",
      "2022-03-20 20:27:08.990302+11:00\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now(tz_SYD))\n",
    "# Instantiate XGB Classifier with default Hyperparams\n",
    "clf_xgb3=xgb.XGBClassifier(random_state=8, use_label_encoder=False, eval_metric='mlogloss')\n",
    "# Fit XGB Classifier\n",
    "clf_xgb3.fit(X_train,y_train)\n",
    "print(clf_xgb3)\n",
    "print(datetime.now(tz_SYD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set Name</th>\n",
       "      <th>ACC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.691360</td>\n",
       "      <td>0.744925</td>\n",
       "      <td>0.700858</td>\n",
       "      <td>0.719348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validate</td>\n",
       "      <td>0.652601</td>\n",
       "      <td>0.687157</td>\n",
       "      <td>0.640138</td>\n",
       "      <td>0.659655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.651550</td>\n",
       "      <td>0.686672</td>\n",
       "      <td>0.638717</td>\n",
       "      <td>0.658627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Set Name       ACC      PREC    RECALL        F1\n",
       "0     Train  0.691360  0.744925  0.700858  0.719348\n",
       "1  Validate  0.652601  0.687157  0.640138  0.659655\n",
       "2      Test  0.651550  0.686672  0.638717  0.658627"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score XGB Classifier\n",
    "perf.score_models(X_train, y_train, X_val, y_val, X_test, y_test, None, False, \"multiclass\", clf_xgb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/xgb_beer_type_prediction.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dump the XGB Classifier for use in the API\n",
    "joblib.dump(clf_xgb3, '../models/xgb_beer_type_prediction.joblib', compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 KNN Model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Tune KNN with Hyperopt to find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space for XGB Hyperopt tuning\n",
    "knnspace = {\n",
    "    'leaf_size' : hp.choice('leaf_size', range(1, 50, 1)),\n",
    "    'n_neighbors' : hp.choice('n_neighbors', range(1, 30, 1)),\n",
    "    'p' : hp.uniform('p', 1, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective for XGB Hyperopt tuning\n",
    "def knnobjective(space):  \n",
    "    clf_knn = KNeighborsClassifier (\n",
    "        leaf_size = int(space['leaf_size']),\n",
    "        n_neighbors = int(space['n_neighbors']),\n",
    "        p = space['p']\n",
    "    )\n",
    "    clf_knn.fit(X_train, y_train)   \n",
    "    y_preds = clf_knn.predict(X_train)\n",
    "    acc = accuracy_score(y_train, y_preds)\n",
    "    return{'loss': 1-acc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-20 20:33:58.651071+11:00\n",
      "100%|██████████| 5/5 [09:48<00:00, 117.75s/trial, best loss: 0.3751202575756928]\n",
      "2022-03-20 20:43:47.415334+11:00\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now(tz_SYD))\n",
    "# Perform Hyperopt search and return best parameters after 5 iterations\n",
    "knnbest = fmin(\n",
    "    fn=knnobjective,   \n",
    "    space=knnspace,       \n",
    "    algo=tpe.suggest,       \n",
    "    max_evals=5\n",
    ")\n",
    "print(datetime.now(tz_SYD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN:  {'leaf_size': 4, 'n_neighbors': 10, 'p': 1.5885049034437508}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best KNN: \", knnbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate KNN Classifier with best Hyperopt Params\n",
    "clf_knn1 = KNeighborsClassifier(\n",
    "    leaf_size = knnbest['leaf_size'],\n",
    "    n_neighbors = knnbest['n_neighbors'],\n",
    "    p = knnbest['p']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-20 20:47:34.922070+11:00\n",
      "KNeighborsClassifier(leaf_size=4, n_neighbors=10, p=1.5885049034437508)\n",
      "2022-03-20 20:47:36.087834+11:00\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now(tz_SYD))\n",
    "# Fit KNN  Classifier with best Hyperopt Params\n",
    "clf_knn1.fit(X_train, y_train)\n",
    "print(clf_knn1)\n",
    "print(datetime.now(tz_SYD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set Name</th>\n",
       "      <th>ACC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.631514</td>\n",
       "      <td>0.657662</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.614906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validate</td>\n",
       "      <td>0.525283</td>\n",
       "      <td>0.545551</td>\n",
       "      <td>0.486109</td>\n",
       "      <td>0.508750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.523372</td>\n",
       "      <td>0.547630</td>\n",
       "      <td>0.484041</td>\n",
       "      <td>0.508357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Set Name       ACC      PREC    RECALL        F1\n",
       "0     Train  0.631514  0.657662  0.587600  0.614906\n",
       "1  Validate  0.525283  0.545551  0.486109  0.508750\n",
       "2      Test  0.523372  0.547630  0.484041  0.508357"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score KNN Classifier\n",
    "perf.score_models(X_train, y_train, X_val, y_val, X_test, y_test, None, False, \"multiclass\", clf_knn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Observations:**\n",
    ">* Accuracy is a little lower than default KNN model but higher than Base model.\n",
    ">* This model is still overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Train and assess a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Pytorch compatible datasets from numpy arrays\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a the Pytorch Classifier\n",
    "model = PytorchMultiClass(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (layer_out): Linear(in_features=32, out_features=105, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the available devices and assign model to the device\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model Criteria\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs and batch size\n",
    "N_EPOCHS = 1000\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-20 21:07:26.257740+11:00\n",
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: 0.1455\t|\tAcc: 1.5%\n",
      "\t(valid)\t|\tLoss: 0.1457\t|\tAcc: 0.9%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: 0.1455\t|\tAcc: 1.3%\n",
      "\t(valid)\t|\tLoss: 0.1457\t|\tAcc: 0.9%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: 0.1455\t|\tAcc: 1.3%\n",
      "\t(valid)\t|\tLoss: 0.1457\t|\tAcc: 0.9%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: 0.1453\t|\tAcc: 2.1%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 5\n",
      "\t(train)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 6\n",
      "\t(train)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 7\n",
      "\t(train)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 8\n",
      "\t(train)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 9\n",
      "\t(train)\t|\tLoss: 0.1453\t|\tAcc: 2.2%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 10\n",
      "\t(train)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 11\n",
      "\t(train)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 12\n",
      "\t(train)\t|\tLoss: 0.1453\t|\tAcc: 2.2%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 13\n",
      "\t(train)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 14\n",
      "\t(train)\t|\tLoss: 0.1453\t|\tAcc: 2.2%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 15\n",
      "\t(train)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 16\n",
      "\t(train)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 17\n",
      "\t(train)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 18\n",
      "\t(train)\t|\tLoss: 0.1453\t|\tAcc: 2.2%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 19\n",
      "\t(train)\t|\tLoss: 0.1453\t|\tAcc: 2.2%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "Epoch: 20\n",
      "\t(train)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n",
      "\t(valid)\t|\tLoss: 0.1452\t|\tAcc: 2.3%\n"
     ]
    }
   ],
   "source": [
    "# Train and test the model\n",
    "print(datetime.now(tz_SYD))\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_acc = test_classification(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.1f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.1f}%')\n",
    "print(datetime.now(tz_SYD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t(test)\t|\tLoss: 0.0103\t|\tAcc: 0.9%\n"
     ]
    }
   ],
   "source": [
    "# Test the model agains the test data set\n",
    "test_loss, test_acc = test_classification(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\t(test)\\t|\\tLoss: {test_loss:.4f}\\t|\\tAcc: {test_acc * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
